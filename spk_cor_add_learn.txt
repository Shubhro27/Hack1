How to find maximum value for a number of keys: use maxBy, but maxBy if used by itself on an array may fail, it should be used with "collect" action,
example (consider word count):
val r1 = sc.textFile("/user/shubhro2705854012/wordCount/wordCountFile.txt")  //reads from HDFS

val r2 = r1.map { x => 
val arr = x.split(" ")   //will split the lines based on SPACE
val mp = arr.map( w => (w,1))  //will form key,value pair as (word, 1)
mp
}.flatMap( y => y)    //will neutralize an iteration so o/p will be array((word1,1),(word2,1)....) instead of array(array(word1,1),array(word2,1)....) 

val r3 = r2.reduceByKey(_+_)   //summation

r3.collect.maxBy(_._2)   //will provide the (key, value) pair by maximum value for a key. _._2 is the 2nd part i.e. value in the key/Value pair.

NOTE: the same applies in case we want to find the minimum value.

---------------------------

How to read file from local file system (i.e. linux file system) if we are logged in to spark-shell:
append the complete path by : "file:///"

val r1 = sc.textFile("file:///home/shubhro2705854012/sparkLocal/tryScalaTrim.txt")
--------------------------

In order to set up the location of the warehouse, we can set up the following property in hive-site.xml:

	<property>
	  <name>hive.metastore.warehouse.dir</name>
	  <value>/apps/hive/warehouse</value>
	</property>


By default, Hive stores data in textFile format, but this can be changed in the following property in hive-site.xml:

	<property>
	  <name>hive.default.fileformat</name>
	  <value>TextFile</value>
	</property>

Following are the Apache Hive different file formats:
1) Text File i.e. Data is stored in lines, with each line being a record. Each lines are terminated by a newline character (\n). "stored as textfile;"
2) Sequence File i.e. Hadoop flat files which stores values in binary key-value pairs. "stored as sequencefile;"
3) RC File i.e. row columnar file format that offers high row level compression rates i.e. If you have requirement to perform multiple rows at a time then you can use RCFile format.
	This file stores data as key-value pairs. "stored as rcfile;"
4) AVRO File i.e. provides data-serialization and data exchange for hadoop, which implies, data exchange between hadoop ecosystem and programs written in different language.
	"stored as avro;"
5) ORC File i.e. Optimized Row Columnar file format, provides a highly efficient way to store data in Hive table. ORC files improves performance when Hive is reading, writing, and 
    processing data from large tables. "stored as orc;"
6) Parquet File i.e. column-oriented binary file format good for queries scanning particular columns within a particular table. This file format uses compressions like Sanppy (default),
   gzip. "stored as parquet;"
   
   
Serde in Hive : https://www.quora.com/What-is-SerDe-in-Hive

Partitions in Hive : https://andr83.io/1123/
			
In real 60K partitions is not a big problem for Hive. I have experience with about 2MM partitions for one Have table and it works pretty fast. 
It is recommend to use ORC format with indexes and bloom filters support.

Performance tuning in Hive:
https://support.treasuredata.com/hc/en-us/articles/360001450788-Hive-Performance-Tuning

#######
Delete an external table with data/Partitions:
1)  ALTER TABLE $tablename SET TBLPROPERTIES('EXTERNAL'='False'); 
	DROP TABLE $tablename;

2) truncate a table:
	TRUNCATE TABLE table_name [PARTITION partition_spec];
	where partition_spec: (partition_column = partition_col_value, partition_column = partition_col_value, ...)
	
3) ALTER TABLE some.table DROP PARTITION (part="some") PURGE;
	hdfs dfs -rm -R /path/to/table/basedir
  
#######
Hive, working with semi structured data (like xml, json):
https://www.guru99.com/data-extraction-hive.html#2

######

Map side join and bucket map join : https://acadgild.com/blog/map-side-joins-in-hive

######
Join Optimization : https://acadgild.com/blog/join-in-hive-optimization

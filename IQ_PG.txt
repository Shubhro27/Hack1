Link-1: https://www.dezyre.com/article/pig-interview-questions-and-answers-for-2018/244

-------------------------------------------------------------------------------------------------
Modes of Execution for Apache Pig:
1) Local Mode   : pig -x local
2) Cluster Mode : pig

Pig programming is done via pig latin. To execute a statement, Pig requires an execution engine. So
Pig Engine (converts statements into MapReduce jobs) -> map Reduce Engine then executes this set of Map-reduce jobs.

Difference between Pig and Hive:
Pig								 		Hive
Pig is a Yahoo Product.			 		Hive is a facebook product.
Pig is a dataflow language.				Hive supports a data warehouse architecture.
Pig resides on client machine.   		Hive resides on server machine.
Pig supports semi structured format		Hive is strictly structured.
Pig implements DAG						Hive executes the code at run time

Difference between Pig and Mapreduce:
Pig										MR
Pig is a scripting language.			MR is a compiled language.
High level of abstraction.				Low level of Abstraction.
Pig uses less lines of coding.			More lines of coding.
Pig implements DAG						MR executes the code at run time

Difference between Pig and SQL
Pig														SQL
Pig resides on HDFS 									SQL resides on DB server
PIG implements DAG, scripting language					SQL is compiled language
Pig built-in can split a data processing stream			SQL cannot
Pig build in allows loading the data for operations		SQL requires interrogating the DB for every transaction.
--------------------------------------------------------------------------------------------------
Mapfile and bloomsMapFile in Hadoop:

mapFile: is a directory which comprises of 2 sequential files: data file and index file. It appends key-Value pairs as key and offset as index.
		 This allows for a fast lookup, as instead of scanning all the records till a key is found, we scan the index, which has lesser entries.
		 
BloomMapFile: is a class which extends MapFile. It uses HBASE table format and expedites the search for a file/block than mapFile.
--------------------------------------------------------------------------------------------------
Complex datatypes in PIG:
1) Maps (KeyValue pairs separated by #)
2) Tuples (uneditable array of heterogeneous elements)
3) Bag (group of tuples) 

Map in more details:
Usually maps are not preferred in PIG. Limitation is one can not lookup variable key in the Map in Pig i.e. key needs to be constant.
ex, e.g. myMap#'keyFoo' is allowed but myMap#$SOME_VARIABLE is not allowed.

We need maps as, usually Hadoop data are the dumps of different data sources from Traditional languages. 
If original data sources contain Maps, the HDFS data would contain a corresponding Map. example,HttpRequest header#'clientIp'.

Handling map datatype:
1) adding in schema as map[chararray]
	example,
		a = LOAD 'pigtest.csv' using PigStorage('|') AS (employee_id:int, email:chararray, name:tuple(first_name:chararray, middle_name:chararray, last_name:chararray), 
														 project_list:bag{project: tuple(project_name:chararray)}, skills:map[chararray]) ;

		b = FOREACH a GENERATE employee_id, email, name.first_name, project_list, skills#'programming' ;

		dump b

2) Using TOMAP() [post version 0.10]
	example,
		I/p:
			001,Robin,22,newyork
			002,BOB,23,Kolkata
			003,Maya,23,Tokyo
			004,Sara,25,London 
			005,David,23,Bhuwaneshwar 
			006,Maggy,22,Chennai
			
		code:
			emp_data = LOAD 'employee_details.txt' USING PigStorage(',') as (id:int, name:chararray, age:int, city:chararray);
			tomap = FOREACH emp_data GENERATE TOMAP(name, age);
			DUMP tomap;
			
		O/p:
			([Robin#22])
			([BOB#23])
			([Maya#23])
			([Sara#25]) 
			([David#23])
			([Maggy#22])
--------------------------------------------------------------------------------------------------
CO-GROUP Example,
	GROUP-BY Operates on only one relation (Bag), CO-GROUP works on more than one relation.
	example,
	1st file: student_details.txt
		001,Rajiv,Reddy,21,9848022337,Hyderabad
		002,siddarth,Battacharya,22,9848022338,Kolkata
		003,Rajesh,Khanna,22,9848022339,Delhi
		004,Preethi,Agarwal,21,9848022330,Pune
		005,Trupthi,Mohanthy,23,9848022336,Bhuwaneshwar
		006,Archana,Mishra,23,9848022335,Chennai
		007,Komal,Nayak,24,9848022334,trivendram
		008,Bharathi,Nambiayar,24,9848022333,Chennai

	2nd file: employee_details.txt
		001,Robin,22,newyork 
		002,BOB,23,Kolkata 
		003,Maya,23,Tokyo 
		004,Sara,25,London 
		005,David,23,Bhuwaneshwar 
		006,Maggy,22,Chennai
		
	STEP-1: load the files into relations:
	student_details = LOAD 'hdfs://localhost:9000/pig_data/student_details.txt' USING PigStorage(',') 
	as (id:int, firstname:chararray, lastname:chararray, age:int, phone:chararray, city:chararray); 
  
	employee_details = LOAD 'hdfs://localhost:9000/pig_data/employee_details.txt' USING PigStorage(',') as (id:int, name:chararray, age:int, city:chararray);
	
	STEP-2: cogroup then on the basis of age,
	cogroup_data = COGROUP student_details by age, employee_details by age;
	
	O/p: (DUMP cogroup_data)
		(21,{(4,Preethi,Agarwal,21,9848022330,Pune), (1,Rajiv,Reddy,21,9848022337,Hyderabad)}, {    })  
		(22,{ (3,Rajesh,Khanna,22,9848022339,Delhi), (2,siddarth,Battacharya,22,9848022338,Kolkata) },{ (6,Maggy,22,Chennai),(1,Robin,22,newyork) })  
		(23,{(6,Archana,Mishra,23,9848022335,Chennai),(5,Trupthi,Mohanthy,23,9848022336 ,Bhuwaneshwar)},{(5,David,23,Bhuwaneshwar),(3,Maya,23,Tokyo),(2,BOB,23,Kolkata)}) 
		(24,{(8,Bharathi,Nambiayar,24,9848022333,Chennai),(7,Komal,Nayak,24,9848022334, trivendram)}, { })  
		(25,{   },{(4,Sara,25,London)})

--------------------------------------------------------------------
How to execute shell commands from within Grunt shell:
1) sh command: example, "sh ls" will list all the files /pig/bin directory.
			   NOTE: with sh, we cannot execute the commands that are a part of the shell environment (example - cd).
2) fs command: we can invoke any FsShell (file system shell) commands from the Grunt shell.
			   example, fs -ls.
			   
How to run a pig script from grunt shell:
1) run command: syntax is run [-param param-name = <param-value>][-param_file file_name] script
	example,
	i/p file: student.txt
				001,Rajiv,Hyderabad
				002,siddarth,Kolkata
				003,Rajesh,Delhi
				
	sample_script.pig:
		student = LOAD 'hdfs://localhost:9000/pig_data/student.txt' USING PigStorage(',') as (id:int,name:chararray,city:chararray);
		
	run this script:
		grunt> run /sample_script.pig
		
	to check the o/p:
		grunt> Dump;

		(1,Rajiv,Hyderabad)
		(2,siddarth,Kolkata)
		(3,Rajesh,Delhi)
		
2) running pig script with params example,
	syntax is : run [-param param-name = <param-value>][-param_file file_name] script
	          OR run [-p = <param-value>][-m file_name] script
			  
	example,
	i/p file: student.txt
				001,Rajiv,Reddy,21,9848022337,Hyderabad
				002,siddarth,Battacharya,22,9848022338,Kolkata
				003,Rajesh,Khanna,22,9848022339,Delhi
				004,Preethi,Agarwal,21,9848022330,Pune
				005,Trupthi,Mohanthy,23,9848022336,Bhuwaneshwar
				006,Archana,Mishra,23,9848022335,Chennai
				007,Komal,Nayak,24,9848022334,trivendram
				008,Bharathi,Nambiayar,24,9848022333,Chennai
				
	params.init (file to hold all parameters)
				fileName='hdfs://horton/user/jgosalia/students.txt'
				cityName='Chennai'
				
	filter.pig
			students = LOAD '$fileName' USING PigStorage(',') AS (id:int, firstname:chararray, lastname:chararray, age:int, phone:chararray, city:chararray);
			students = FILTER students BY city == '$cityName';
			DUMP students;
			
			
	Run command:
	1) pig -param fileName='hdfs://horton/user/jgosalia/students.txt' -param cityName='Chennai' filter.pig
	2) pig -param_file params.init filter.pig
		
What is difference between run command and exec command:
with run, the statements from the script are available in the command history.

------------------------------------------------------------------------
What are Pig diagnostic operators:

By diagnostic operators, we mean operators which verify the result of a LOAD command.
there are 4 operators as such,
1) Dump operator
2) Describe operator : view the schema of a relation.
3) Explanation operator : display the logical, physical, and MapReduce execution plans of a relation.
						  so, the output of "explain student;" will comprise of:
						  LogicalPlanOptimizer, "New Logical Plan", "Physical Plan", "map-Reduce Plan".
4) Illustration operator : "illustrate student;" provides step-by-step execution of a sequence of statements.

-------------------------------------------------------------------------
What are the kind of joins available in Pig:
1) self join
2) inner join
3) Outer join:
	a) Full outer join : grunt> outer_full = JOIN customers BY id FULL OUTER, orders BY customer_id;
	b) Left outer join : grunt> outer_left = JOIN customers BY id LEFT OUTER, orders BY customer_id;
	c) Right outer join: grunt> outer_right = JOIN customers BY id RIGHT, orders BY customer_id;

	
what is CROSS Operator: it provides the cartesian product of 2 relations. example, grunt> Relation3_name = CROSS Relation1_name, Relation2_name;

What is Union and what is split operator in PIG?
Union will merge the contents of 2 relations. example, grunt> Relation_name3 = UNION Relation_name1, Relation_name2;
Split will split the content of a relation into 2 or more relations based on a condition.
example, SPLIT Relation1_name INTO Relation2_name IF (condition1), Relation2_name (condition2),
		 SPLIT student_details into student_details1 if age<23,student_details2 if (22<age and age>25);
		 
------------------------------------------------------------------------
What is difference between COUNT() and COUNT_STAR()
	COUNT() ignores NULL elements but COUNT_STAR() considers NULL elements (tuples).
	example,
	1) Input file has
		, , , , , , , 
		001,Rajiv,Reddy,21,9848022337,Hyderabad,89 
		002,siddarth,Battacharya,22,9848022338,Kolkata,78 
		003,Rajesh,Khanna,22,9848022339,Delhi,90 
		004,Preethi,Agarwal,21,9848022330,Pune,93 
		005,Trupthi,Mohanthy,23,9848022336,Bhuwaneshwar,75 
		006,Archana,Mishra,23,9848022335,Chennai,87 
		007,Komal,Nayak,24,9848022334,trivendram,83 
		008,Bharathi,Nambiayar,24,9848022333,Chennai,72
		
	2) load the file into a relation:
		grunt> student_details = LOAD 'hdfs://localhost:9000/pig_data/student_details.txt' USING PigStorage(',')
				as (id:int, firstname:chararray, lastname:chararray, age:int, phone:chararray, city:chararray, gpa:int);
				
	3) group:
		grunt> student_group_all = Group student_details All;
		
		o/p: 
			(all,{(8,Bharathi,Nambiayar,24,9848022333,Chennai,72),
			(7,Komal,Nayak,24,9848022 334,trivendram,83),
			(6,Archana,Mishra,23,9848022335,Chennai,87),
			(5,Trupthi,Mohan thy,23,9848022336,Bhuwaneshwar,75),
			(4,Preethi,Agarwal,21,9848022330,Pune,93),
			(3 ,Rajesh,Khanna,22,9848022339,Delhi,90),
			(2,siddarth,Battacharya,22,9848022338,Ko lkata,78),
			(1,Rajiv,Reddy,21,9848022337,Hyderabad,89),
			( , , , , , , )}) 
			
	4) grunt> student_count = foreach student_group_all  Generate COUNT_STAR(student_details.gpa);
	
		o/p: 9 // i.e. it counted the NULL tuple too.
		
What does TOKENIZE do?
	It splits a string (based on delimter) and returns a bag of tuples where each tuple is the split string.
	grunt> TOKENIZE(expression [, 'field_delimiter'])
	example,
		1) I/p file: 
				001,Rajiv Reddy,21,Hyderabad
				002,siddarth Battacharya,22,Kolkata 
				003,Rajesh Khanna,22,Delhi 
				004,Preethi Agarwal,21,Pune 
				005,Trupthi Mohanthy,23,Bhuwaneshwar 
				006,Archana Mishra,23 ,Chennai 
				007,Komal Nayak,24,trivendram
				008,Bharathi Nambiayar,24,Chennai 			
				
		2) Load the file into a relation.

		3) grunt> student_name_tokenize = foreach student_details  Generate TOKENIZE(name);
			O/p:
			({(Rajiv),(Reddy)})
			({(siddarth),(Battacharya)})
			({(Rajesh),(Khanna)})
			({(Preethi),(Agarwal)})
			({(Trupthi),(Mohanthy)})
			({(Archana),(Mishra)})
			({(Komal),(Nayak)})
			({(Bharathi),(Nambiayar)})

Can we load zipped file in PIG?
	Yes, we can do it with both BinStorage() and TextLoader() 
	example,
	grunt> data = LOAD 'hdfs://localhost:9000/pig_data/employee.txt.zip' USING PigStorage(','); 
	grunt> data = LOAD 'hdfs://localhost:9000/pig_data/employee.txt.zip' USING TextLoader;
	grunt> store data INTO 'hdfs://localhost:9000/pig_Output/data.bz' USING PigStorage(',');

What is TOP() used for in PIG?
It is used to get the top N tuples in a BAG based on a field value.This returns a bag containing required columns.
grunt> TOP(topN,column,relation)

example,
1) Input file
		001,Robin,22,newyork 
		002,BOB,23,Kolkata 
		003,Maya,23,Tokyo 
		004,Sara,25,London 
		005,David,23,Bhuwaneshwar 
		006,Maggy,22,Chennai 
		007,Robert,22,newyork 
		008,Syam,23,Kolkata 
		009,Mary,25,Tokyo 
		010,Saran,25,London 
		011,Stacy,25,Bhuwaneshwar 
		012,Kelly,22,Chennai
		
2) load and group
	grunt> emp_group = Group emp_data BY age;
	
	O/p:
		(22,{(12,Kelly,22,Chennai),(7,Robert,22,newyork),(6,Maggy,22,Chennai),(1,Robin, 22,newyork)}) 
		(23,{(8,Syam,23,Kolkata),(5,David,23,Bhuwaneshwar),(3,Maya,23,Tokyo),(2,BOB,23, Kolkata)}) 
		(25,{(11,Stacy,25,Bhuwaneshwar),(10,Saran,25,London),(9,Mary,25,Tokyo),(4,Sara, 25,London)})

3)  get the top two records of each group arranged based on "id"
	grunt> data_top = FOREACH emp_group { 
					   top = TOP(2, 0, emp_data);      #0 is for ID position.
					   GENERATE top; 
					}
					
	O/p:
	({(7,Robert,22,newyork),(12,Kelly,22,Chennai)}) 
	({(5,David,23,Bhuwaneshwar),(8,Syam,23,Kolkata)}) 
	({(10,Saran,25,London),(11,Stacy,25,Bhuwaneshwar)})

----------------------------------------------------------------------------------------
Embedding Pig Script from Unix Shell, Java and Python:
1) Unix shell: 
	a) pig  -f /home/Scripts/PigScripts/pig_dcnt$x.pig --param timestamp=$timestamp1
	   example,
			#!/bin/sh
			x=1
			while [ $x -le 3 ]
			do
				echo "pig_dcnt$x.pig will be  run"
				pig  -f /home/Scripts/PigScripts/pig_dcnt$x.pig --param timestamp=$timestamp1
				x=$(( $x + 1 ))
			done
			
	b) 
		example,
			#!/bin/bash
			pig pig_script_file1.pig
			pig pig_script_file2.pig

		NOTE: used exec command (example, exec pig_script_file1.pig) in shell script but it just enters into grunt shell and not executing the the pig scripts.

2) Java: Pig provides a PigServer class, using which we can embedded Pig in Java or any other scripting languages. 
		 Details: https://acadgild.com/blog/embedding-pig-java/
	a) create an object: 
		PigServer pigServer = new PigServer(ExecType.MAPREDUCE);  //ExecType gives the mode to run PIG (i.e. local or mapreduce mode)
	b) "runQuery" runs your Pig script:
		runQuery(pigServer);
	c) PigServer provides default methods to register pig queries:
		i.e to include a pigLatin script, use pigServer.registerQuery method provided by the PigServer.
			pigServer.registerQuery("input1 = LOAD '/input' as (line:chararray);"); 
			pigServer.registerQuery("words = foreach input1 generate FLATTEN(TOKENIZE(line)) as word;");
			pigServer.registerQuery("word_groups = group words by word;");
			pigServer.registerQuery("word_count = foreach word_groups generate group, COUNT(words);");
			pigServer.registerQuery("ordered_word_count = order word_count by group desc;");
			pigServer.registerQuery("store ordered_word_count into '/wct_output';");
	d) Using the Properties class, we need to give the HDFS path
		example, props.setProperty("fs.default.name", "hdfs://localhost:9000");
		
	NOTE: setup MAVEN before running.
	
3) Python: pig -embedded jython myjob.py OR USE Python UDFs from within PIG.
		   also check https://www.safaribooksonline.com/library/view/programming-pig/9781449317881/ch09.html
		   
		   
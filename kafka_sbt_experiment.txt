import org.apache.spark._
import org.apache.spark.streaming.StreamingContext
import org.apache.spark.streaming.Seconds
import org.apache.spark.streaming.kafka.KafkaUtils
object WordCount {
  def main( args:Array[String] ){
    val conf = new SparkConf().setMaster("local[*]").setAppName("KafkaReceiver")
    val ssc = new StreamingContext(conf, Seconds(10))
    val kafkaStream = KafkaUtils.createStream(ssc, "localhost:2181","spark-streaming-consumer-group", Map("sb-wrdcnt-topic" -> 5))
    //need to change the topic name and the port number accordingly
    val words = kafkaStream.flatMap(x => x._2.split(" "))
    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)
    kafkaStream.print()  //prints the stream of data received
    wordCounts.print()   //prints the wordcount result of the stream
    ssc.start()
    ssc.awaitTermination()
  }
}

1) create a topic sb-wrdcnt-topic
2) start the producer
   
   
name := "Spark_Stream_App1"
version := "1.5.2"
scalaVersion := "2.10.4"
libraryDependencies += "org.apache.spark" %% "spark-sql" % "2.2.0" // specify ur dependencies in ur sbt file

libraryDependencies += "org.apache.spark" %% "spark-mllib" % "2.1.0" % "provided"

libraryDependencies += "org.apache.spark" %% "spark-streaming" % "2.1.0" % "provided"

libraryDependencies += "org.apache.spark" %% "spark-streaming" % "2.1.0";"org.apache.spark" %% "spark-streaming-kafka-0.9.0.2.3.4.0-3485" % "2.10.0"

kafka_2.10-0.9.0.2.3.4.0-3485.jar

--------------------------------------------
sb-wrdcnt-topic

kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic sb-wrdcnt-topic

spark-submit \
--class "WordCount" \
--master local[4] \
target/scala-2.10/spark_stream_app1_2.10-1.5.2.jar
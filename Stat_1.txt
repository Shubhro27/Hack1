Multivariate analysis: i.e. analysis over combination of variables. example, covariance, correlation, regression (linear and non-linear).

1) Covariance: This helps understand dependency between 2 variables. example, if business question is "if temperature is 30 C, what will be the cold-drink sales",
			   first we will have to establish/prove dependency between temperature and cold-drink sales. 
			   
			   Prediction model can only be based on dependency between variables. No dependency implies no prediction. 
			   i.e. we need to understand how i/p variable is influencing target variable. example,
			   based on height, weight and age, we need to predict cholestrol levels, if we apply,
			   cov(age,cholestrol) = 1.23     i.e. positive dependency
			   cov(height, cholestrol) = 0.0  i.e. zero dependency
			   cov(weight,cholestrol) = -0.34 i.e. negative dependency
			   
			   so we can ignore height for predicting cholestrol levels.
			   
			   there can be 3 possible values for covariance,
			   =0 : implies no dependency between the variables. i.e. change in value of one variable does not impact value of other variable. i.e. both variables are INDEPENDENT.
			   >0 : implies positive dependency i.e. increase in value of one variable will cause increase in value of other variable. similar for DECREASE.
					example, cov(temperature, cold-drink sales) will be +VE.
			   <0 : implies negative dependency i.e. increase in value of one variable will cause decrease in value of other variable. similar for DECREASE.
					example, cov(temperature, sweater sales) will be -VE.
			   
			   NOTE: is covariance is very close to ZERO, then also we can imply NO DEPENDENCY. example, 0.000073, -0.000058 will also imply NO DEPENDENCY.
			   
			   Problem with covariance is that it can just explain positive OR negative OR no dependencies. How strongly/weakly the variables are associated/bonded/dependent 
			   cannot be explained with covariance.
					 
2) Correlation: Correlation also helps understand dependency between 2 variables. This however helps overcome the disadvantage of covariance.
				i.e. we can use to derive strong dependency or weak dependency.
				
				correlation is measured by "correlation coefficient" (SYMBOL is "r") where -1 <= r <= 1 (i.e. r lies between -1 and +1)
				There are 3 possible values similar to covariance. However based on range of values, we can explain dependencies in 7 ways,
				-1____________-0.5___________0____________0.5_____________+1
				 |     |               |     |      |              |      |
                 3     7               6     1      4              5      2    -> positions explaining dependency. 
                                                                                7 (range between -1 to -0.5)
																				6 (range between -0.5 to 0)
																				4 (range between 0 to 0.5)
																				5 (range between 0.5 to 1)
			   
			    when r = 1         i.e. perfect positive correlation- same percentage reflection happens between values of 2 variables i.e. y = f(x)
																	   ex, if x =(10,20,30,15) then y =(1,2,3,1.5)  i.e. y = 10% of x
																	       if x =(10,100,30,90) then y =(20,200,60,90) i.e. y = 2x 
																		   so both variables move in the same direction and reflection of changes is also same.
				    r = -1         i.e  perfect negative correlation - same percentage reflection happens between values of 2 variables but in opposite direction i.e. y = -f(x)
																	   ex, if x =(10,20,30,15) then y =(-1,-2,-3,-1.5)  i.e. y = minus(10% of x)
																	       if x =(10,100,30,90) then y =(-20,-200,-60,-90) i.e. y = -2x 	
																		   i.e. both move in the opposite direction but reflection of changes is also same.
					0 < r <=0.5   i.e. weak positive correlation     - both variables will move in same direction but reflection is NOT close (i.e. FAR reflection)
																	   ex, x increases by 70% but y increased by only 10%.
																	       x increased by 7% but y increased by 80%
																		   i.e. high change (increment/decrement) in x will cause less change in y OR
																		        high change in y will cause less change in x
																			so less change in one variable will cause high change in other variable.
					 r> 0.5        i.e. strong positive correlation - both variables move in the same direction BUT the percentage reflection is not same but close
					                                                   ex, if x increases by 10% (10,11,12,13) but y increases by 20% (1,2,4,8)
																	       x increases by 10% and y by 9%, x decreases by 11% but y decreases by 13%.
																		   so less change in one variable will cause less change in other variable and
																		   high change in one variable will cause high change in other variable.
					 -0.5 <= r < 0 i.e. weak negative correlation   - both variables move in opposite direction but reflection of changes is Far.
																	   ex, if x gets incremented by 70%, but y gets decreased by 10%
																		   if x gets decremented by 7% but y increased by 80%
																		   i.e. high increment in one variable will cause less decrement in other variable.
																		   OR low decrement in one variable will cause high increment in other variable.
					 r < -0.5      i.e. strong negative correlation	- both variables move in opposite direction but reflection of changes is close.
                                                                      ex, x increased by 10% but y decreased by 9%
																		  x decreased by 9% but y increased by 8% 
			         r = 0         i.e. no dependency
					 
	graphical representations of correlation:
	1) perfect positive correlation: angle of the curve is exactly 45 degree with x-axis.
	2) strong positive correlation: angle of the curve is > or < than 45 degree with x-axis but the angle will be close to 45 degree (ex, 43, 47).
	3) weak positive correlation:  angle of the curve is > or < than 45 degree with x-axis but the angle will be far way from 45 degree (ex, 20, 75).
	
	4) perfect negative correlation: the line will form a triange with x and y axis and where it meets x and y axis, the angle will be exactly 45 degree.
	5) strong negative correlation: the line will form a triange with x and y axis and where it meets x axis, the angle will be close to 45 degree.
	6) weak negative correlation: the line will form a triange with x and y axis and where it meets x axis, the angle will be far away from 45 degree (i.e. close to 90 or 0 deg).
	
----------------------------------------------------
Predictions & forecasting:

Predictive analysis comprises of 2 models -  prediction and forecasting.

Prediction is estimating the value of one variable (i.e. target variable) based on values of other variable (i.e input variable).
example, based on temperature, estimate cold drink sales.
         based on age, experience, designation, industry estimate annual income.
		 
Predictions are used to predict,
1) regression problems: in this case target variable is continuous (i.e. values change). I/p variables should also be continuous.
            regression models primary are of 2 types,
			a) linear regression
			b) non linear regression
			
			there are others like ridge regression, lasso regression.
2) classification problems: target variable is a classifier (i.e. any one of the given options i.e. discrete variables). example, tomorrow will it rain (yes/no).
                            Classifiers (options) can be 2 or more.
			classification models include,
			a) logistic regression
			b) Naive bays classifier
			c) decision tree
			d) random forest
			e) support vector machines (SVM)
		    f) ADABooster	
		 
Forecasting is estimating feature depending on timeline. Input and target variables are same for forecasts.
example, based on a list of temperature for last 20 days, estimate tomorrow's temperature.
         based on last 100 days of Infy's share values, estimate Infy share price for tomorrow.

Forecasting models include,
1) time series analysis: following a series of timelines i.e. tomorrow depends on today's data and today depends of yesterday's data and so on
	example, if we have data for last 1 month, we can use if to predict the next day's data.
	TSA models include,
	a) Auto regression (AR)
	b) Integration
	c) Moving average (MA)
	d) ARMA: combination of AR and MA
	e) ARIMA: combination of AR, Integration and MA
	there are more models.
	




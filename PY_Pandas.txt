Pandas:
shortform for "Panel Data System" is built on top of NumPy and SciPy

Pandas has,
1) a tabular data structure that can hold both homogenous and heterogenous data.
2) Very good indexing capabilities that makes data alignment and merging easy.
3) Good time series functionality. No need to use different data structures for time series and cross sectional data. Allows for both ordered and unordered time-series data.
4) A host of statistical functions developed around NumPy and pandas that makes a researcher’s task easy and fast.
5) Programming is lot simpler and faster.
6) Easily handles data manipulation and cleaning.
7) Easy to expand and shorten data sets. Comprehensive merging, joins, and group by functionality to join multiple data sets.

In order to be able to use Pandas and NumPy, first import it using import statement
import pandas as pd                         # This will import pandas into your workspace
import numpy as np                          # We will be using numpy functions so import numpy

There are 2 key components in Panda:
1) Series : Series is a 1-D array like object. pandas attaches a label to each of the values. If the labels are not provided by the programmer, 
			then pandas assigns labels ( 0 for first element, 1 for second element and so on).
			A benefit of assigning labels to data values is that it becomes easier to perform manipulations on the dataset as the whole dataset 
			becomes more of a dictionary where each value is associated with a label.
			
			example, 
			import pandas as pd
			s = pd.Series((1,2,3,4,5)) //series object for tuple
			s1 = pd.Series(list('abcdef')) //series object for list.
			print s
			print s.values
			print s.index    //default index is 0 : N-1
			print s1
			print s1.values
			print s1.index
			
			o/p:
			print s will give:
			0	1
			1	2
			2	3
			3	4
			4	5
			
			print s.index will give: 0 1 2 3 4 
			print s.values will give : 1 2 3 4 5
			
			Print s1 will give:
			0	a
			1	b
			2	c
			3	d
			4	e
			5	f
			
			print s1.index will give: 0 1 2 3 4 5
			print s1.values will give: a b c d e f
			
			
		** NOTE: details mentioned later in this learning doc	
					 
2) Dataframe: 2-D tabular data structure with integrated indexing. Supports both homogeneous and heterogeneous columns.
			example,
			import pandas as pd
			pop_data = {'FL':{2010:18.8,2011:19.1},'GA':{2008:9.7,2010:9.7,2011:9.8}}
			pop = pd.DataFrame(pop_data)
			print pop
			
			o/p:
					FL		GA
			2008	NaN		9.7
			2010	18.8	9.7
			2011	19.1	9.8
			
3) Panel: 3-D matrix. It has 3 axes,
		a) items: axis-0 and corresponds to the dataframe.
		b) major_axis: axis-1 and corresponds to rows of each dataframe.
		c) minor_axis: axis-2 and corresponds to columns of each dataframe.
		
		example,
		import pandas as pd
		import numpy as np
		data = np.random.rand(2,4,5)
		p = pd.Panel(data)
		print p

-------------------
Lambda Functions: i.e. functions without a name which are used as soon as they have been created.
				Syntax: lambda argument_list: expression (usually functions like filter(),map(),reduce())
						where,
						argument_list: comma separated arguments.
						expression: arithmetic expression using arguments.
						
						
				example,
				f = lambda x,y: x+y
				print (f(1,1))
				
				o/p:
				2
				
what is map() function?
map function syntax is - map(func,sequence) where func -> name of function and sequence is a list, array etc
map function applies to all elements in the sequence i.e. the function will be applied on each element.
map function returns a new list of elements changed by func

example (function usage of map vs lambda usage of map),
def far(T):
 return((float(9)/5)*T + 32)
 
def celsius(T):
 return((float(5)/9)*(T - 32)
 
temp = (36.5,37,37.5,39)
f = map(far,temp)
c = map (celsius,f)

with lambda,
celsius = (36.5,37,37.5,39)
far = map(lambda x:(float(9)/5)*x+32,celsius)
C = map( lambda x:(float(5)/9)*(x-32),far)

-------------------------------------------------
Pandas Series (revisited): definition already present.

example 1,
	import pandas as pd
	import numpy as np
	series1 = pd.Series([10,20,30,40])   #NOTE: Series keyword is case sensitive. "series" will error out.
	print (series1)
	print (series1.values)   #will give the data type object of the Series and the values
	print (series1.index)    #will give the index data type (usually Int64) and list of index values and data type.
	print ("\n")
	series2 = pd.Series([1,2,3,4,5],index = [10,20,30,40,50])  #creating custom indexes
	print (series2)
	print (series2.values)
	print (series2.index) 

o/p:
	0    10
	1    20
	2    30
	3    40
	#
	dtype: int64
	[10 20 30 40]
	#
	Int64Index([0, 1, 2, 3], dtype='int64')

	10    1
	20    2
	30    3
	40    4
	50    5
	#
	dtype: int64
	[1 2 3 4 5]
	#
	Int64Index([10, 20, 30, 40, 50], dtype='int64')

example 2, Series can accept heterogeneous datatypes. In case a series has heterogenous items, dtype: object
	series3 = pd.Series([1,2,3,"four",5],index = [10,20,30,40,50])
	print (series3)
	print (series3.values)
	print (series3.index)

	o/p:
	10       1
	20       2
	30       3
	40    four
	50       5
	#
	dtype: object
	[1 2 3 'four' 5]
	#
	Int64Index([10, 20, 30, 40, 50], dtype='int64')

example 3, string index and heterogeneous index,
	series4 = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])
	print (series4)
	print (series4.values)
	print (series4.index)
	print ("\n")
	#
	series5 = pd.Series([1,2,3,4,5],index = ['one',2,'three','four',5])
	print (series5)
	print (series5.values)
	print (series5.index)	

	o/p:
	a    1
	b    2
	c    3
	d    4
	e    5
	dtype: int64
	[1 2 3 4 5]
	Index([u'a', u'b', u'c', u'd', u'e'], dtype='object')
	#
	one      1
	2        2
	three    3
	four     4
	5        5
	dtype: int64
	[1 2 3 4 5]
	Index([u'one', 2, u'three', u'four', 5], dtype='object')	


Accessing specific elements in a series: this can be done using the same way as numpy.
example,
	series3 = pd.Series([1,2,3,"four",5],index = [10,20,30,40,50])
	print (series3[[10,40]])
	print (series3[[10:40]])   //THIS WILL ERROR. SyntaxError: invalid syntax
	series5 = pd.Series([1,2,3,4,5],index = ['one',2,'three','four',5])
	print (series5[2])
	print (series5['three'])
    print (series5['two'])  //THIS WILL ERROR. KeyError: 'two'
	print (series3[60])     //THIS WILL ERROR as 60 is not listed in index.
	
	o/p:
	#series3
	10       1
	20       2
	30       3
	40    four
	50       5	

	10       1
	40    four
	dtype: object

	#series5
	one      1
	2        2
	three    3
	four     4
	5        5

	2
	9
	
However, if we give a [[]], the keyError is bypassed and o/p becomes NaN
	example,
	series3 = pd.Series([1,2,3,"four",5],index = [10,20,30,40,50])
	print (series3[[60]])
	print (series3['two'])
	print (series3[['two',60,45]]) 
	
	O/p:
	60    NaN
	#
	two   NaN
	#
	two    NaN
	60     NaN
	45     NaN
	
to show the elements for an index range. ex, show all elements between 2 to 4 index values.
example,
	series8 = pd.Series([1,2,3,4,5])
	print (series8.ix[2:4])
	print (series8.ix[2:6])   //If index is out of bounds, elements are displayed only till the maximum index value.

	o/p:
	2    3
	3    4
	4    5
	dtype: int64
	
Arithmetic operations on each element in a series.
example,
	series6 = pd.Series([1,2,3,4,5])
	print (series6 + 10)
	print (series6 ** 2)
	print (np.sqrt(series6))
	series7 = series6 + 10
	print (series7)   #Assignment to a different series. same result as (series6 + 10).

	O/p:
	0    11
	1    12
	2    13
	3    14
	4    15
	dtype: int64
	0     1
	1     4
	2     9
	3    16
	4    25
	dtype: int64
	0    1.000000
	1    1.414214
	2    1.732051
	3    2.000000
	4    2.236068
	dtype: float64
	
Filtering elements of a series.
example,
		print (series7[series7 > 11])
		print (series2[[series2>30]]) #i.e. [[]], will error with too many indices.
	
	o/p:
	1    12
	2    13
	3    14
	4    15
	dtype: int64
	
If you have a dictionary, you can create a Series data structure from that dictionary,
example,
	years = [91, 90, 92, 93, 94, 95, 96, 97]
	f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11, 96:13}
	firm1 = pd.Series(f1,index=years)                     # Extra element in VALUE not an issue. The extra element is substituted with NaN
	print(firm1)
	f2 = {90:14,92:9, 93:13, 94:5}
	firm2 = pd.Series(f2,index=years)
	print(firm2)
	print (pd.isnull(firm2))  							  # isnull() function to find out if there are any missing values in the data structure.
	print (~pd.isnull(firm2))                             # "~" is NOT Operator. gives opposite of previous statement.
	
	o/p:
	91     9
	90     8
	92     7
	93     8
	94     9
	95    11
	96    13
	97   NaN
	dtype: float64
	#
	91   NaN
	90    14
	92     9
	93    13
	94     5
	95   NaN
	96   NaN
	97   NaN
	dtype: float64
	#
	91     True
	90    False
	92    False
	93    False
	94    False
	95     True
	96     True
	97     True
	dtype: bool
	
	NOTE: NaN stands for missing or NA values in pandas. Make use of isnull() function to find out if there are any missing values in the data structure.
	
	
If we are operating on 2 different series, we do not have to worry about data alignment. Pandas takes care of that.
example, calculate the sum of common words in combined files
	dict1 = {'finance': 10, 'earning': 5, 'debt':8}
	dict2 = {'finance' : 8, 'compensation':4, 'earning': 9}
	count1 = pd.Series(dict1)
	count2 = pd.Series(dict2)
	print (count1)
	print (count2)
	print (count1 + count2) #
	
	o/p:
	debt        8
	earning     5
	finance    10
	dtype: int64
	#
	compensation    4
	earning         9
	finance         8
	dtype: int64
	#
	compensation     NaN
	debt             NaN
	earning         14.0
	finance         18.0
	
-----------------------------------------------------------------------------
Data Frame (revisited):
is a tabular data structure in which data is laid out in rows and column format (similar to a CSV and SQL file),
DF is logical extension of Series data structures. 
In contrast to Series, where there is one index, a DataFrame object has one index for column and one index for rows. 
This allows flexibility in accessing and manipulating data.

example,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	print(data) 	

	O/p: # each key forms a column and each row is automatically indexed from 0-n
		company				price	ticker
	0	American Express	95		AXP
	1	Cisco				25		CSCO
	2	Walt Disney			85		DIS
	3	Microsoft			41		MSFT
	4	Walmart				78		WMT

Note: all the arrays in a DF should be of the same size,
example,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney']})  /#i.e. company has only 3 values
	print(data)
						 
	O/p:
	ValueError: arrays must all be same length

to print data for a specific key,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	print(data['company'])
	print(data.company)  //same result as above  
	
	o/p:
	0    American Express
	1               Cisco
	2         Walt Disney
	3           Microsoft
	4             Walmart
	Name: company, dtype: object
	
to print a row corresponding to an index,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	print (data.ix[2])       # Print the row corresponding to the given Index
	print (data.ix[2:4])     #range of indices
	
	o/p:
	company    Walt Disney
	price               85
	ticker             DIS
	Name: 2, dtype: object
	
		   company  price ticker
	2  Walt Disney     85    DIS
	3    Microsoft     41   MSFT
	4      Walmart     78    WMT
	
filtering DF based on "key"/"columns":
example,
	data.ix[data.ticker=='DIS']            # Print the row corresponding to the ticker that is 'DIS'
	print(data)

	o/p:
		company		price	ticker
	2	Walt Disney	85		DIS

adding a new column to a DF,
example,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	data['Year'] = 2014                    # Add additional column Year. Populate value of 2014 in all the rows.
	print(data)
	data['pricesquared'] = data.price**2      # Square all the prices and add another column 'pricesquared'.
	print(data)
	del data['pricesquared']                  # Delete column 'pricesquared'
	print(data)
	data['pricesquared'] = np.NaN             # Create column 'pricesquared' with NaN values
	print(data)
	data['sequence'] = np.arange(2014,2024,2) # Add column 'sequence'												
	print(data)
	
O/p:
	company				price	ticker	Year
0	American Express	95		AXP		2014
1	Cisco				25		CSCO	2014
2	Walt Disney			85		DIS		2014
3	Microsoft			41		MSFT	2014
4	Walmart				78		WMT		2014
#
	company				price	ticker	Year	pricesquared
0	American Express	95		AXP		2014	9025
1	Cisco				25		CSCO	2014	625
2	Walt Disney			85		DIS		2014	7225
3	Microsoft			41		MSFT	2014	1681
4	Walmart				78		WMT		2014	6084
#
	company				price	ticker	Year
0	American Express	95		AXP		2014
1	Cisco				25		CSCO	2014
2	Walt Disney			85		DIS		2014
3	Microsoft			41		MSFT	2014
4	Walmart				78		WMT		2014
#
	company				price	ticker	Year	pricesquared
0	American Express	95		AXP		2014	NaN
1	Cisco				25		CSCO	2014	NaN
2	Walt Disney			85		DIS		2014	NaN
3	Microsoft			41		MSFT	2014	NaN
4	Walmart				78		WMT		2014	NaN
#
	company				price	ticker	Year	pricesquared	sequence
0	American Express	95		AXP		2014	NaN				2014
1	Cisco				25		CSCO	2014	NaN				2016
2	Walt Disney			85		DIS		2014	NaN				2018
3	Microsoft			41		MSFT	2014	NaN				2020
4	Walmart				78		WMT		2014	NaN				2022


adding a new row to dataframe, sorting it by column:
example,
	import pandas as pd
	np.random.seed(2)
	dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])
	print(dataframe)
	print(dataframe.sort_values(by='two'))

	o/p:
		 one	     two	    three
	0	-0.416758	-0.056267	-2.136196
	1	1.640271	-1.793436	-0.841747
	2	0.502881	-1.245288	-1.057952
	#sorted values
			one       two     three
	1  1.640271 -1.793436 -0.841747
	2  0.502881 -1.245288 -1.057952
	0 -0.416758 -0.056267 -2.136196


example-2,
	import pandas as pd
	s1 = pd.Series([5, 6, 7])
	s2 = pd.Series([7, 8, 9])
	df = pd.DataFrame([list(s1), list(s2)],  columns =  ["A", "B", "C"])
	print(df)
	df.loc[-1] = [2, 3, 4]  # adding a row
	df.index = df.index + 1  # shifting index
	df = df.sort_index()  # sorting by index
	print(df)
	
	o/p,
	   A  B  C
	0  5  6  7
	1  7  8  9
	#
	   A  B  C
	0  2  3  4
	1  5  6  7
	2  7  8  9


example-2,
	import pandas as pd
	datax = pd.DataFrame({'Value':[2.8,2.5,2.2,2.3],'frequency':[10,20,30,40]})
	print(datax)
	datax.loc[-1,'frequency']=35  			#add a new row with frequency = 35 and index = -1
	print(datax)
	datax =datax.reset_index(drop=True)		#reset index in the dataframe
	print(datax)
	datax = datax.sort_values('frequency')  #sort by frequency column
	print(datax)
	
	OR
	df = pd.DataFrame({'Value':[2.8,2.5,2.2,2.3],'frequency':[10,20,30,40]})
	df.loc[-1, 'Frequency'] = 35
	print(df)
	df = df.sort_values('Frequency').reset_index(drop=True)
	print (df)
	
	o/p:
	   Value  frequency
	0    2.8         10
	1    2.5         20
	2    2.2         30
	3    2.3         40
		Value  frequency
	 0    2.8       10.0
	 1    2.5       20.0
	 2    2.2       30.0
	 3    2.3       40.0
	-1    NaN       35.0
	   Value  frequency
	0    2.8       10.0
	1    2.5       20.0
	2    2.2       30.0
	3    2.3       40.0
	4    NaN       35.0
	   Value  frequency
	0    2.8       10.0
	1    2.5       20.0
	2    2.2       30.0
	4    NaN       35.0
	3    2.3       40.0


Using Numpy functions inside DataFrame Objects:
example,
	import pandas as pd
	import numpy as np
	# Create array of 3*3 dimensionality using standard normally distributed random vales
	#np.random.seed(0)   #will seed and will the NOT change random numbers in consecutive numbers. 
	dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])  
	print(dataframe)
	print(np.abs(dataframe))                   # Absolute value
	f = lambda x:x.max()-x.min()               # lambda function to get range i.e. max - min.
	print (abs(dataframe).apply(f))            # applies to column (BY-DEFAULT)
	print (abs(dataframe).apply(f,axis=1))     #axis=1, applies to row
	
	
	o/p:
		one			two			three
	0	-0.057379	0.244387	0.128660
	1	0.342184	1.080002	-0.528302
	2	0.370405	-0.319412	1.427701
	#
		one			two			three
	0	0.057379	0.244387	0.128660
	1	0.342184	1.080002	0.528302
	2	0.370405	0.319412	1.427701
	# column range
	one      0.313026
	two      0.835614
	three    1.299041
	dtype: float64
	#row range
	0    0.187008
	1    0.737818
	2    1.108289
	dtype: float64
	
example-2:
	print(dataframe)
	dataframe.sum()                          # Column wise sum
	dataframe.sum(axis=1)                    # Row wise sum
	dataframe.cumsum()                 		 # Get cumulative sum for columns 
	
o/p:
#column-wise
one      0.655210
two      1.004977
three    1.028059
dtype: float64
#row-wise
0    0.315668
1    0.893883
2    1.478694
dtype: float64
#cumlative
        one       two     three
0       0.043830  1.328110  0.739642
1       0.040941  1.518764  2.111642
2      -0.331633  1.103796  3.745047
i.e. each column value is added to the next column value. if dataframe.cumsum(axis=1), the sum of consecutive rows. 

	
function to create a series having mean, max and min of a set of DF rows using numpy functions.
example,
	def f(x):
		return pd.Series([np.mean(x), x.max(), x.min()], index=['mean','max','min'])
	print(dataframe)
	print(dataframe.apply(f,axis=1))
	
o/p:
	one       two     three
0 -0.057379  0.244387  0.128660
1  0.342184  1.080002 -0.528302
2  0.370405 -0.319412  1.427701
#
	mean		max			min
0	0.105223	0.244387	-0.057379
1	0.297961	1.080002	-0.528302
2	0.492898	1.427701	-0.319412
	
describe the characteristics of a dataframe,
example, (when the data frame contains numbers)
	dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three']) 
	dataframe.describe()
	
	o/p:
				one       two     three
	count  3.000000  3.000000  3.000000
	mean   0.170356  1.069239 -0.593476
	std    0.994400  0.551264  0.298080
	min   -0.975123  0.432745 -0.849494
	25%   -0.150436  0.906642 -0.757096
	50%    0.674251  1.380539 -0.664698
	75%    0.743096  1.387486 -0.465467
	max    0.811941  1.394433 -0.266237
	
example, (when the dataframe is combination of string and number columns, describe will only aggregate the numeric fields in the DF
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	
	data['Year'] = [2014] 
	print(data)
	
	o/p:
			  price
	count   5.00000
	mean   64.80000
	std    30.18609
	min    25.00000
	25%    41.00000
	50%    78.00000
	75%    85.00000
	max    95.00000

			  price  Year
	count   5.00000     5
	mean   64.80000  2014
	std    30.18609     0
	min    25.00000  2014
	25%    41.00000  2014
	50%    78.00000  2014
	75%    85.00000  2014
	max    95.00000  2014

example, (when the data frame contains ONLY string),
	data = pd.DataFrame({'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	print(data.describe())
	
	o/p:
				company ticker
	count             5      5
	unique            5      5
	top     Walt Disney    DIS
	freq              1      1

To conclude,
Describe will give - count, mean, std, min, max FOR NUMBERS
					 count, unique, top, freq FOR STRINGS

-----------------------------------------------------------------------------------------------------------					 
concatenate 2 dataframes:
You can pass a number of data structures to DataFrame such as a ndarray, lists, dict, Series, and another DataFrame.
example,
df1 = pd.DataFrame({'price':[95, 25, 85, 41, 78],
						 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
						 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})

a) concatenating a series,
	example,
		series1 = pd.Series(['bank','telecom','entertainment','software','retail'])
		df1['category'] = series1
		print df1
		
	o/p:
				company  price ticker       category
	0  American Express     95    AXP           bank
	1             Cisco     25   CSCO        telecom
	2       Walt Disney     85    DIS  entertainment
	3         Microsoft     41   MSFT       software
	4           Walmart     78    WMT         retail
	
b) concatenating a list (or tuple)
	example,
		list1 = ['bank','telecom','entertainment','software','retail']
		df1['category'] = list1
		print(df1)
		
	o/p:
				company  price ticker       category
	0  American Express     95    AXP           bank
	1             Cisco     25   CSCO        telecom
	2       Walt Disney     85    DIS  entertainment
	3         Microsoft     41   MSFT       software
	4           Walmart     78    WMT         retail
	
c) concatenating a dataframe,
	example,
	1) column-wise concatenation,
		series1 = pd.Series(['bank','telecom','entertainment','software','retail'])
		series2 = pd.Series(['LA','NW','SF','SD','IL','MO'])
		df2 = pd.DataFrame([])
		df2['category'] = series1
		df2['origin'] = series2
		print(df2)
		print("\n")
		print("concatenate 2 DF column wise")
		df_col_merged =pd.concat([df1, df2], axis=1)
		print(df_col_merged)
		print("\n")
		
	o/p:
				company  price ticker
	0  American Express     95    AXP
	1             Cisco     25   CSCO
	2       Walt Disney     85    DIS
	3         Microsoft     41   MSFT
	4           Walmart     78    WMT


			category origin
	0           bank     LA
	1        telecom     NW
	2  entertainment     SF
	3       software     SD
	4         retail     IL


	concatenate 2 DF column wise
				company  price ticker       category origin
	0  American Express     95    AXP           bank     LA
	1             Cisco     25   CSCO        telecom     NW
	2       Walt Disney     85    DIS  entertainment     SF
	3         Microsoft     41   MSFT       software     SD
	4           Walmart     78    WMT         retail     IL
	
	2) row-wise concatenation:
		example,
			df3 = pd.DataFrame({'price':[90,20],'company':['southwest airlines','red lobster']})
			print(df3)   #the column names are same as df1
			print("\n")
			df_row_merged =pd.concat([df1, df3], axis=0) //column not defined will be added as NaN
			print(df_row_merged)
			
		o/p:
					  company  price ticker
		0    American Express     95    AXP
		1               Cisco     25   CSCO
		2         Walt Disney     85    DIS
		3           Microsoft     41   MSFT
		4             Walmart     78    WMT
		0  southwest airlines     90    NaN
		1         red lobster     20    NaN
		
		#column names are case sensitive,
		example,
			df3 = pd.DataFrame({'Price':[90,20],'Company':['southwest airlines','red lobster']})
			print(df3)
			print("\n")
			df_row_merged =pd.concat([df1, df3], axis=0)
			print(df_row_merged)
			
		o/p:
					  Company  Price           company  price ticker
		0                 NaN    NaN  American Express   95.0    AXP
		1                 NaN    NaN             Cisco   25.0   CSCO
		2                 NaN    NaN       Walt Disney   85.0    DIS
		3                 NaN    NaN         Microsoft   41.0   MSFT
		4                 NaN    NaN           Walmart   78.0    WMT
		0  southwest airlines   90.0               NaN    NaN    NaN
		1         red lobster   20.0               NaN    NaN    NaN

	
d) Merging 2 dataframes.
		example-1, (merge on the basis of key)
			left_frame = pd.DataFrame({'key': range(5),'left_value': ['a', 'b', 'c', 'd', 'e']})
			right_frame = pd.DataFrame({'key': range(2, 7),'right_value': ['f', 'g', 'h', 'i', 'j']})
			print(left_frame)
			print("\n")
			print(right_frame)
			pd.merge(left_frame, right_frame, on='key')
			
		o/p:
			   key left_value
			0    0          a
			1    1          b
			2    2          c
			3    3          d
			4    4          e   
			#
			   key right_value
			0    2           f
			1    3           g
			2    4           h
			3    5           i
			4    6           j
			#
			   key left_value right_value
			0    2          c           f
			1    3          d           g
			2    4          e           h
		
		example-2, (merge on the basis of multiple keys)
			left = pd.DataFrame({
					 'id':[1,2,3,4,5],
					 'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],
					 'subject_id':['sub1','sub2','sub4','sub6','sub5']})
			right = pd.DataFrame(
					 {'id':[1,2,3,4,5],
					 'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
					 'subject_id':['sub2','sub4','sub3','sub6','sub5']})
			print pd.merge(left, right, on='subject_id')
			
		o/p:
				Name_x   id   subject_id   Name_y
			0    Alice    4         sub6    Bryce
			1   Ayoung    5         sub5    Betty
			
		example, for different kind of joins,
		i/p:
			Name  id   subject_id
		0   Alex   1         sub1
		1    Amy   2         sub2
		2  Allen   3         sub4
		3  Alice   4         sub6
		4  Ayoung  5         sub5

			Name  id   subject_id
		0  Billy   1         sub2
		1  Brian   2         sub4
		2  Bran    3         sub3
		3  Bryce   4         sub6
		4  Betty   5         sub5

		Merge_Method	SQL_Equivalent		Description
		left 			LEFT OUTER JOIN 	Use keys from left object 
		right 			RIGHT OUTER JOIN 	Use keys from right object 
		outer 			FULL OUTER JOIN 	Use union of keys 
		inner 			INNER JOIN 			Use intersection of keys 
		
		Left join : print pd.merge(left, right, on='subject_id', how='left')
		Right join: print pd.merge(left, right, on='subject_id', how='right')
		Outer join: print pd.merge(left, right, how='outer', on='subject_id')
		Inner join: print pd.merge(left, right, on='subject_id', how='inner')
		
		o/p:
			#left
				Name_x   id_x   subject_id   Name_y   id_y
			0     Alex      1         sub1      NaN    NaN
			1      Amy      2         sub2    Billy    1.0
			2    Allen      3         sub4    Brian    2.0
			3    Alice      4         sub6    Bryce    4.0
			4   Ayoung      5         sub5    Betty    5.0
			#right
				Name_x  id_x   subject_id   Name_y   id_y
			0      Amy   2.0         sub2    Billy      1
			1    Allen   3.0         sub4    Brian      2
			2    Alice   4.0         sub6    Bryce      4
			3   Ayoung   5.0         sub5    Betty      5
			4      NaN   NaN         sub3     Bran      3
			#outer
				Name_x  id_x   subject_id   Name_y   id_y
			0     Alex   1.0         sub1      NaN    NaN
			1      Amy   2.0         sub2    Billy    1.0
			2    Allen   3.0         sub4    Brian    2.0
			3    Alice   4.0         sub6    Bryce    4.0
			4   Ayoung   5.0         sub5    Betty    5.0
			5      NaN   NaN         sub3     Bran    3.0
			#inner
				Name_x   id_x   subject_id   Name_y   id_y
			0      Amy      2         sub2    Billy      1
			1    Allen      3         sub4    Brian      2
			2    Alice      4         sub6    Bryce      4
			3   Ayoung      5         sub5    Betty      5
		


-----------------------------------------------------------------------------------------------------------
Pandas for handling missing data in a dataframe:

1) how to create a dataFrame from a set of series, INITIALIZE to NaN and then populate it with series data as columns.

	example,
		import numpy as np
		import pandas as pd
		years = [90, 91, 92, 93, 94, 95]
		f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}
		firm1 = pd.Series(f1,index=years)
		print firm1
		print("\n")
		f2 = {90:14,92:9, 93:13, 94:5}
		firm2 = pd.Series(f2,index=years)
		print firm2
		print("\n")
		f3 = {93:10, 94:12, 95: 13}
		firm3 = pd.Series(f3,index=years)
		print firm3
		print("\n")
		df3 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)
		print df3
		print("\n")
		df3.Firm1 = firm1
		df3.Firm2 = firm2
		df3.Firm3 = firm3
		print df3
		
	o/p:
	90     8
	91     9
	92     7
	93     8
	94     9
	95    11
	dtype: int64
	90    14
	91   NaN
	92     9
	93    13
	94     5
	95   NaN
	dtype: float64
	90   NaN
	91   NaN
	92   NaN
	93    10
	94    12
	95    13
	dtype: float64
		 Firm1 Firm2 Firm3
	90   NaN   NaN   NaN
	91   NaN   NaN   NaN
	92   NaN   NaN   NaN
	93   NaN   NaN   NaN
	94   NaN   NaN   NaN
	95   NaN   NaN   NaN

		 Firm1  Firm2  Firm3
	90      8     14    NaN
	91      9    NaN    NaN
	92      7      9    NaN
	93      8     13     10
	94      9      5     12
	95     11    NaN     13
	
2) drop NaN values from a series or DataFrame.
	1) delete the entire row from series or DF which has NaN
		years = [90, 91, 92, 93, 94, 95]
		f2 = {90:14,92:9, 93:13, 94:5}
		firm2 = pd.Series(f2,index=years)
		print(firm2)
		nadeleted = firm2.dropna()
		print(nadeleted)
		cleandf3 = df3.dropna(axis=1)          # DF3 row created above. REMOVES COLUMNS having even 1 NaN value.
		#cleandf3 = df3.dropna(axis=0)         # df3.dropna() will REMOVE ROWS having even 1 NaN value.
		print(cleandf3)
		
		o/p:
		90    14
		91   NaN
		92     9
		93    13
		94     5
		95   NaN
		dtype: float64
		#91 and 95th rows are deleted
		90    14
		92     9
		93    13
		94     5
		dtype: float64
		#DF3
			 Firm1  Firm2  Firm3
		90      8     14    NaN
		91      9    NaN    NaN
		92      7      9    NaN
		93      8     13     10
		94      9      5     12
		95     11    NaN     13
		#df3.dropna(axis=1) 
			Firm1
		90      8
		91      9
		92      7
		93      8
		94      9
		95     11
		#df3.dropna(axis=0)
			Firm1  Firm2  Firm3
		93      8     13     10
		94      9      5     12
		
	3) drop a row only if ALL the values in the row is NaN. ex, clean2 = df3.dropna(how='all')

	4) Define threshold of NaN i.e. number of NaN for a row/column is > threshhold.
			thresholddf1 = df3.dropna(axis=1,thresh=2)    # Define threshold. In this case column having >= 2 NaN, drop the column
			thresholddf2 = df3.dropna(axis=0,thresh=2)    # Define threshold. In this case row having >= 2 NaN, drop the row
			
	5) fill the NaN with another value.
		example,
		fillna1 = df3.fillna(0)      # Fill all NaN values with 0
		print(fillna1)
		fillna2 = df3.fillna({'Firm1':8, 'Firm2': 10, 'Firm3':14})	# We can specify what value should be replaced
		print(fillna2)				
		
	o/p:
				 Firm1  Firm2  Firm3
			90      8     14    NaN
			91      9    NaN    NaN
			92      7      9    NaN
			93      8     13     10
			94      9      5     12
			95     11    NaN     13
			##### replaced with ZERO
				Firm1  Firm2  Firm3
			90      8     14      0
			91      9      0      0
			92      7      9      0
			93      8     13     10
			94      9      5     12
			95     11      0     13
			##### replace with different values
				Firm1  Firm2  Firm3
			90      8     14     14
			91      9     10     14
			92      7      9     14
			93      8     13     10
			94      9      5     12
			95     11     10     13
			
		example 2,
		#Forward fill and backward fill
		fillna3 = df3.fillna(method='ffill')
		print(fillna3)
		fillna4 = df3.fillna(method='bfill')
		print(fillna4)
		
	o/p:
				 Firm1  Firm2  Firm3
			90      8     14    NaN
			91      9    NaN    NaN
			92      7      9    NaN
			93      8     13     10
			94      9      5     12
			95     11    NaN     13
			#####forward fill
				Firm1  Firm2  Firm3
			90      8     14    NaN
			91      9     14    NaN
			92      7      9    NaN
			93      8     13     10
			94      9      5     12
			95     11      5     13
			#####backward fill
				Firm1  Firm2  Firm3
			90      8     14     10
			91      9      9     10
			92      7      9     10
			93      8     13     10
			94      9      5     12
			95     11    NaN     13
			
	6) Interpolate: is usually used to replace a Nan, but it can also be used to populate a value with avg of 2 values.
		as shown below
		
		example-1, replace NaN
			years = [1988, 1989, 1990, 1991, 1992, 1993, 1994]
			f1 = {1990:8, 1992:11}
			firm1 = pd.Series(f1,index=years)
			f2 = {1990:5,1992:3}
			firm2 = pd.Series(f2,index=years)
			f3 = {1990:4, 1992:2}
			firm3 = pd.Series(f3,index=years)
			df9 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)
			df9
			df9.Firm1 = firm1
			df9.Firm2 = firm2
			df9.Firm3 = firm3
			print (df9)
			print (df9.interpolate())
			#print(df9.interpolate().fillna(method='bfill')) //for backward fill and forward fill together.

			O/p:
				  Firm1  Firm2  Firm3
			1988    NaN    NaN    NaN
			1989    NaN    NaN    NaN
			1990    8.0    5.0    4.0
			1991    NaN    NaN    NaN
			1992   11.0    3.0    2.0
			1993    NaN    NaN    NaN
			1994    NaN    NaN    NaN
			###forward fill
				  Firm1  Firm2  Firm3
			1988    NaN    NaN    NaN
			1989    NaN    NaN    NaN
			1990    8.0    5.0    4.0
			1991    9.5    4.0    3.0
			1992   11.0    3.0    2.0
			1993   11.0    3.0    2.0
			1994   11.0    3.0    2.0
			###backward fill and forward fill together
				  Firm1  Firm2  Firm3
			1988    8.0    5.0    4.0
			1989    8.0    5.0    4.0
			1990    8.0    5.0    4.0
			1991    9.5    4.0    3.0
			1992   11.0    3.0    2.0
			1993   11.0    3.0    2.0
			1994   11.0    3.0    2.0
			
		example-2, use interpolate to fill values,
		(add a line at frequency 35 with a value interpolated linearly between frequencies 30 and 40.)
			datax = pd.DataFrame({'Value':[2.8,2.5,2.2,2.3],'frequency':[10,20,30,40]})
			datax.loc[-1,'frequency']=35
			datax =datax.reset_index(drop=True)
			datax = datax.sort_values('frequency')
			print(datax)
			datax = datax.interpolate()
			print(datax)
			
		o/p:
			   Value  frequency
			0    2.8       10.0
			1    2.5       20.0
			2    2.2       30.0
			4    NaN       35.0
			3    2.3       40.0
			   Value  frequency
			0   2.80       10.0
			1   2.50       20.0
			2   2.20       30.0
			4   2.25       35.0
			3   2.30       40.0
		
------------------------------------------------
Linspace:
provides result of the formula = (Max - Initial)/[number of elements - 1]
example,
	array(np.linspace(2,4,9))

o/p:
[2 2.25 2.75 3.0 3.25 3.50 3.75 4.0]

example 2,
arr = np.linspace(0,15,40)
print (arr)
add = arr+1
print(add)  #will add 1 to each element of the array.

o/p:
[  0.           0.38461538   0.76923077   1.15384615   1.53846154 ......,14.23076923  14.61538462  15.        ]
[  1.           1.38461538   1.76923077   2.15384615   2.53846154,......,15.61538462  16.        ]

----------------------------------------------------
Transposing a dataframe in Pandas:
example,
	data = pd.DataFrame({'price':[95, 25, 85, 41, 78],
							 'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],
							 'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})
	print(data)
	data1 = data.T
	print(data1)
	del data1[4]
	print(data1)

	o/p:
				company  price ticker
	0  American Express     95    AXP
	1             Cisco     25   CSCO
	2       Walt Disney     85    DIS
	3         Microsoft     41   MSFT
	4           Walmart     78    WMT
							0      1            2          3        4
	company  American Express  Cisco  Walt Disney  Microsoft  Walmart
	price                  95     25           85         41       78
	ticker                AXP   CSCO          DIS       MSFT      WMT
	
	company  American Express  Cisco  Walt Disney  Microsoft
	price                  95     25           85         41
	ticker                AXP   CSCO          DIS       MSFT

example-2,
	years = [90, 91, 92, 93, 94, 95]
	f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}
	firm1 = pd.Series(f1,index=years)
	#print(firm1)
	f2 = {90:14,92:9, 93:13, 94:5}
	firm2 = pd.Series(f2,index=years)
	#print(firm2)
	f3 = {93:10, 94:12, 95: 13}
	firm3 = pd.Series(f3,index=years)
	#print(firm3)
	df1 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)
	df1.Firm1 = firm1
	df1.Firm2 = firm2
	df1.Firm3 = firm3
	print(df1)
	dft = df1.T
	print (dft)
		
	o/p:
			 90   91   92    93    94    95
	Firm1   8.0  9.0  7.0   8.0   9.0  11.0
	Firm2  14.0  NaN  9.0  13.0   5.0   NaN
	Firm3   NaN  NaN  NaN  10.0  12.0  13.0

			91   92    93    94    95
	Firm1  9.0  7.0   8.0   9.0  11.0
	Firm2  NaN  9.0  13.0   5.0   NaN
	Firm3  NaN  NaN  10.0  12.0  13.0
	
----------------------------------------------------------------------------
Setting column as index,

example,
	if we have a dataframe (data_gender) as,
			   Year  Total  Males  Females
		0   2000/01   1054    309      741
		1   2001/02   1019    284      731
		2   2002/03   1275    427      848
		3   2003/04   1711    498     1213
		4   2004/05   2035    589     1442
		5   2005/06   2564    746     1786
		6   2006/07   3862   1047     2807
		7   2007/08   5018   1405     3613
		8   2008/09   7988   2077     5910
		9   2009/10  10571   2495     8074
		10  2010/11  11574   2919     8654
		11  2011/12  11736   2993     8740
		
	to set the 'Year' as column,
	data_gender.set_index('Year',inplace=True)   # 'inplace=True': updates data_gender
	data_gender1 = data_gender.set_index('Year')  # will create a new data frame 
----------------------------------------------------------------------------
Reindexing a dataframe:

example-1,
	years = [90, 91, 92, 93, 94, 95]
	f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}
	firm1 = pd.Series(f1,index=years)
	#print(firm1)
	f2 = {90:14,92:9, 93:13, 94:5}
	firm2 = pd.Series(f2,index=years)
	#print(firm2)
	f3 = {93:10, 94:12, 95: 13}
	firm3 = pd.Series(f3,index=years)
	#print(firm3)
	df1 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)
	df1.Firm1 = firm1
	df1.Firm2 = firm2
	df1.Firm3 = firm3
	print(df1)
	reindexdf1 = df1.reindex([88,89,90,91,92,93,94,95,96,97,98])
	print(reindexdf1)
	
	o/p:
		Firm1  Firm2  Firm3
	90      8   14.0    NaN
	91      9    NaN    NaN
	92      7    9.0    NaN
	93      8   13.0   10.0
	94      9    5.0   12.0
	95     11    NaN   13.0
	#### re-index
		Firm1  Firm2  Firm3
	88    NaN    NaN    NaN
	89    NaN    NaN    NaN
	90    8.0   14.0    NaN
	91    9.0    NaN    NaN
	92    7.0    9.0    NaN
	93    8.0   13.0   10.0
	94    9.0    5.0   12.0
	95   11.0    NaN   13.0
	96    NaN    NaN    NaN
	97    NaN    NaN    NaN
	98    NaN    NaN    NaN
	
	#re-indexing,
	print(df9)
	reindexdf9 = df9.reindex(np.arange(1988,1998))
	print(reindexdf9)
	reindexdf9 = df9.reindex(['a','b','c','d'])  //all will be NaN
	
	o/p,
		  Firm1  Firm2  Firm3
	1988    NaN    NaN    NaN
	1989    NaN    NaN    NaN
	1990    8.0    5.0    4.0
	1991    NaN    NaN    NaN
	1992   11.0    3.0    2.0
	1993    NaN    NaN    NaN
	1994    NaN    NaN    NaN
	1995    NaN    NaN    NaN
	1996    NaN    NaN    NaN
	1997    NaN    NaN    NaN
	#
	   Firm1  Firm2  Firm3
	a    NaN    NaN    NaN
	b    NaN    NaN    NaN
	c    NaN    NaN    NaN
	d    NaN    NaN    NaN
	
example-2,
	years1 = [90, 91, 92, 93, 94, 95]
	f4 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}
	firm4 = pd.Series(f4,index=years1)
	f5 = {90:14,91:12, 92:9, 93:13, 94:5, 95:8}
	firm5 = pd.Series(f5,index=years1)
	f6 = {90:8, 91: 9, 92:9,93:10, 94:12, 95: 13}
	firm6 = pd.Series(f6,index=years1)
	df2 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years1)
	df2.Firm1 = firm4
	df2.Firm2 = firm5
	df2.Firm3 = firm6
	print(df2)
	reindexdf2 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98],fill_value=0)
	print(reindexdf2)
	
	o/p:
		Firm1  Firm2  Firm3
	88      0      0      0
	89      0      0      0
	90      8     14      8
	91      9     12      9
	92      7      9      9
	93      8     13     10
	94      9      5     12
	95     11      8     13
	96      0      0      0
	97      0      0      0
	98      0      0      0
	
----------------------------------------------------------------------------
Hierarchal Indexing:
allows you to have index on an index (multiple index).
This helps select subsets of data and perform independent analyses on them.

example,
	import numpy as np
	import pandas as pd
	#
	np.random.seed(0)
	h_i_data = pd.Series(np.random.rand(10),index=[['Ind1','Ind1','Ind1','Ind1','Ind2','Ind2','Ind2','Ind3','Ind3','Ind3'],
												[1,2,3,4,1,2,3,1,2,3]])
	print(h_i_data)
	h_i_data['Ind3'] #prints only the sub-indexes and values against 'Ind3'
	h_i_data['Ind1':'Ind2'] #prints for the range.
	h_i_data[['Ind1','Ind3']] #prints for Ind1 and Ind3

	O/p:
	Ind1  1    0.548814
		  2    0.715189
		  3    0.602763
		  4    0.544883
	Ind2  1    0.423655
		  2    0.645894
		  3    0.437587
	Ind3  1    0.891773
		  2    0.963663
		  3    0.383442
	dtype: float64
	#
	1    0.891773
	2    0.963663
	3    0.383442
	dtype: float64
	#range
	Ind1  1    0.548814
		  2    0.715189
		  3    0.602763
		  4    0.544883
	Ind2  1    0.423655
		  2    0.645894
		  3    0.437587
	dtype: float64
	#
	Ind1  1    0.548814
		  2    0.715189
		  3    0.602763
		  4    0.544883
	Ind3  1    0.891773
		  2    0.963663
		  3    0.383442
	dtype: float64

example-2,
	import pandas as pd
	print(h_i_data[:,3])
	print(h_i_data[:,4])   #will provide values only for 'Ind1' as Ind2,Ind3 does not have [4]
	print(h_i_data[:,5])   #KeyError: 5, i.e. there is no [5] in any of the index.
	
o/p:
Ind1    0.602763
Ind2    0.437587
Ind3    0.383442
dtype: float64
Ind1    0.544883
dtype: float64

-------------------------------------------------------------
Stack() and Unstack():
The stack method turns column names into index values, 
and the unstack method turns index values into column names.

example, (unstacking)
	print (h_i_data)
	h_i_data.unstack(level=0) # level '0' is 1st level of indexing in hierarchal indexing.
							  # h_i_data.unstack() is same.
	h_i_data.unstack(level=1) # level '1' is 2nd level of indexing in hierarchal indexing.

o/p:
	Ind1  1    0.548814
		  2    0.715189
		  3    0.602763
		  4    0.544883
	Ind2  1    0.423655
		  2    0.645894
		  3    0.437587
	Ind3  1    0.891773
		  2    0.963663
		  3    0.383442
	dtype: float64
	#level=0
		   Ind1      Ind2      Ind3
	1  0.548814  0.423655  0.891773
	2  0.715189  0.645894  0.963663
	3  0.602763  0.437587  0.383442
	4  0.544883       NaN       NaN
	#level=1
				 1         2         3         4
	Ind1  0.548814  0.715189  0.602763  0.544883
	Ind2  0.423655  0.645894  0.437587       NaN
	Ind3  0.891773  0.963663  0.383442       NaN
	

example, (stacking)
	print(h_i_data.unstack(level=1))   
	print(h_i_data.unstack(level=1).stack())  #(level=0), will also produce the same results.
	
	o/p:
				 1         2         3         4
	Ind1  0.548814  0.715189  0.602763  0.544883
	Ind2  0.423655  0.645894  0.437587       NaN
	Ind3  0.891773  0.963663  0.383442       NaN
	Ind1  1    0.548814
		  2    0.715189
		  3    0.602763
		  4    0.544883
	Ind2  1    0.423655
		  2    0.645894
		  3    0.437587
	Ind3  1    0.891773
		  2    0.963663
		  3    0.383442
	dtype: float64
	
example of sum ing in heirarchal index levels,
	h_i_data.sum()  //sum all the values
	h_i_data.sum(level=1)
	h_i_data.sum(level=0)
	
	o/p:
	6.157662833145425
	#
	1    1.864241
	2    2.324746
	3    1.423792
	4    0.544883
	#
	Ind1   -0.625953
	Ind2    1.842805
	Ind3   -0.342347
	
---------------------------------------------------------------
I/o in Pandas:

Reading a CSV file:
example,
	roedatacsv = pd.read_csv(your_local_path+'roedata_Sc.csv')  #creates a series
	#roedatacsv     											#will show the entire record.
	print(roedatacsv.head(5))                        
	
	o/p:
		Industry Name,Number of firms,ROE
	0	Advertising,65,16.51%
	1	Aerospace/Defense,95,21.60%
	2	Air Transport,25,42.68%
	3	Apparel,70,17.87%
	4	Auto & Truck,26,22.05%
	5	Auto Parts,75,17.54%
	
	location_df = roedatacsv['Industry Name,Number of firms,ROE'].apply(lambda x: pd.Series(x.split(',')))
	location_df.columns = ['Industry Name','Number of firms','ROE']
	print(location_df)
	
	o/p:
	Industry Name			Number of firms	ROE
	0	Advertising			65				16.51%
	1	Aerospace/Defense	95				21.60%
	2	Air Transport		25				42.68%
	3	Apparel				70				17.87%
	4	Auto & Truck		26				22.05%
	5	Auto Parts			75				17.54%
	6	Bank				7				15.03%
	7	Banks (Regional)	721				9.52%
	8	Beverage			47				27.62%
	9	Beverage (Alcoholic)19				18.28%
	10	Biotechnology		349				6.77%
	11	Broadcasting		30				74.10%
	.
	.
	.
	
	in case u do not want to use the first row as header, you use 'name',
	i/p csv file, Pandas_file.csv
		X,Y,Z,Value
		18,55,1,70
		18,55,2,67
		18,57,2,75
		18,58,1,35
		19,54,2,70
		
	dem_csv1 = pd.read_csv('Pandas_file.csv')
	print (dem_csv1)	
	dem_csv2 = pd.read_csv('Pandas_file.csv',names=['A','B','C','D'])
	print (dem_csv2)
	
	o/p:
		X   Y  Z  Value
	0  18  55  1     70
	1  18  55  2     67
	2  18  57  2     75
	3  18  58  1     35
	4  19  54  2     70
	#with custom header
		A   B  C      D
	0   X   Y  Z  Value
	1  18  55  1     70
	2  18  55  2     67
	3  18  57  2     75
	4  18  58  1     35
	5  19  54  2     70
	
	if header than the 1st row in csv file, u use header = '<row-number>'
	dem_csv = pd.read_csv('Pandas_file.csv',header=1)
	print (dem_csv)	

	o/p:
	   18  55  1  70
	0  18  55  2  67
	1  18  57  2  75
	2  18  58  1  35
	3  19  54  2  70
	
If the file does not have a header, then you can either let pandas assign default headers or you can specify custom headers. 
If you want industry name to be the index of DataFrame, you can achieve that.
		  
example,
	roedatacsv = pd.read_csv( your_local_path+'roedata.csv', index_col = 'Industry Name' )
	print(roedatacsv)
	
	o/p:
						Number of firms	ROE
	Industry Name		
	Advertising			65				16.51%
	Aerospace/Defense	95				21.60%
	Air Transport		25				42.68%
	Apparel				70				17.87%
	Auto & Truck		26				22.05%
	
	
Selecting only specific columns from the dataset: (usecols)
example,
	roedatacsv = pd.read_csv(your_local_path+'roedata.csv', usecols = ['Industry Name','ROE'] )
	print(roedatacsv)
	
	o/p:
	    Industry Name		ROE
	0	Advertising			16.51%
	1	Aerospace/Defense	21.60%
	2	Air Transport		42.68%
	3	Apparel				17.87%
	4	Auto & Truck		22.05%
	5	Auto Parts			17.54%
	6	Bank				15.03%
	7	Banks (Regional)	9.52%
	8	Beverage			27.62%
	9	Beverage (Alcoholic)18.28%
	10	Biotechnology		6.77%
	11	Broadcasting		74.10%
	.
	.
	.	

Importing only selected rows,
example,
	roedatacsv = pd.read_csv(your_local_path+'roedata.csv',nrows=50)
	roedatacsv
	
	o/p:
		Industry Name			Number of firms	ROE
	0	Advertising				65				16.51%
	1	Aerospace/Defense		95				21.60%
	2	Air Transport			25				42.68%
	.
	.
	47	Information Services	71				22.24%
	48	Insurance (General)		26				4.08%
	49	Insurance (Life)		27				6.08%
	
skipping rows from dataset:
	i/p csv file, Pandas_file.csv
			X,Y,Z,Value
			18,55,1,70
			18,55,2,67
			18,57,2,75
			18,58,1,35
			19,54,2,70

	example,
		import pandas as pd
		df=pd.read_csv("Pandas_file.csv", skiprows=2)
		print df
	
	o/p:
	#Actual dataframe
		X   Y  Z  Value
	0  18  55  1     70
	1  18  55  2     67
	2  18  57  2     75
	3  18  58  1     35
	4  19  54  2     70	
	
	#skipped 2 rows from top
	   18  55  2  67
	0  18  57  2  75
	1  18  58  1  35
	2  19  54  2  70

----
Reading from text file,
example,
	capm_dem_data = pd.read_table(your_local_path+'capm_dem.txt',nrows = 50, delimiter=' ',header = None)
	print(capm_dem_data)
 
	o/p:
		0		1		2			3
	0	195710	880211	-0.012605	0.003871
	1	195710	880212	-0.008511	0.007406
	2	195710	880216	0.008584	0.001411
	.
	.
	.
	49	195710	880226	-0.008547	0.001747
	
example-2, ( if we skip the header )
	capm_dem_data = pd.read_table(your_local_path+'capm_dem.txt',nrows = 5, delimiter=' ')
	print(capm_dem_data)
	
	o/p:
	   195710  880211  -0.012605  0.003871
	0  195710  880212  -0.008511  0.007406
	1  195710  880216   0.008584  0.001411
	2  195710  880217  -0.004255  0.002414
	3  195710  880218   0.000000  0.002845
	4  195710  880219   0.008547  0.004753
	
Separator, (same as delimiter)
	crsp_data = pd.read_table(your_local_path+'crsp.output', sep='\s+', header = None)
	crsp_data
	
	example-2
	i/p:raw.csv
	number|colour|(a|1)|animal
	1|green|x|dog
	2|blue|y|cat
	3|red|z|owl
	
	data = pd.read_csv('raw.csv',sep='|')
	df = pd.read_csv('raw.csv', sep='|', skiprows=1, names=["number", "colour", "(a|1)", "animal"])
	print df
	
	o/p:
			number colour (a|1) animal
	0       1  		green     x    dog
	1       2   	blue      y    cat
	2       3    	red       z    owl
	
----
Writing data to csv file,
roedata = pd.read_csv(your_local_path+'roedata.csv')
print(roedata)
roedata.to_csv(your_local_path+'roedatawrite89.csv')
	
Writing data to text file,
import numpy as np
import pandas as pd
np.savetxt(r'c:\data\np.txt', df.values, fmt='%d')


##############################################################################################################
Pandas Assignment:
##############################################################################################################
import numpy as np
import pandas as pd

1. Write a Python program to read .xls file through Excelfiles.
An. code,
	xls = pd.ExcelFile('obes-phys-acti-diet.xls')
	print(xls.sheet_names)
	
	o/p:
	[u'Chapter 7', u'7.1', u'7.2', u'7.3', u'7.4', u'7.5', u'7.6', u'7.7', u'7.8', u'7.9', u'7.10']
	
----------------------------------------------------------------------------------------------
2. Write a Python program to print sheet names present in the xls file

An. code,
	xls = pd.ExcelFile('obes-phys-acti-diet.xls')
	print(xls.sheet_names)
	
	o/p:
	[u'Chapter 7', u'7.1', u'7.2', u'7.3', u'7.4', u'7.5', u'7.6', u'7.7', u'7.8', u'7.9', u'7.10']	
	
----------------------------------------------------------------------------------------------
3. Write a Python program to create a list of six columns:
	Year
	Total
	Males
	Females
	Nan
	None
	
An. code,
	obes_cols = ['Year','Total','Males','Females','Nan','None']
----------------------------------------------------------------------------------------------
4. Write a python program to parse the data and read the six columns present in 7.1 sheet of data and skip first six rows and set skipfooter=14 and the column names as
   the list defined above. Assign the dataframe to data_gender.
   
An. code,
	df1 = pd.read_excel(xls, '7.1',header=None,skiprows = 6)
	df1.columns = obes_cols
	data_gender = df1[0:12]
	print(data_gender)
	
	o/p:
		   Year  Total  Males  Females  Nan  None
	0   2000/01   1054    309      741  NaN   NaN
	1   2001/02   1019    284      731  NaN   NaN
	2   2002/03   1275    427      848  NaN   NaN
	3   2003/04   1711    498     1213  NaN   NaN
	4   2004/05   2035    589     1442  NaN   NaN
	5   2005/06   2564    746     1786  NaN   NaN
	6   2006/07   3862   1047     2807  NaN   NaN
	7   2007/08   5018   1405     3613  NaN   NaN
	8   2008/09   7988   2077     5910  NaN   NaN
	9   2009/10  10571   2495     8074  NaN   NaN
	10  2010/11  11574   2919     8654  NaN   NaN
	11  2011/12  11736   2993     8740  NaN   NaN
----------------------------------------------------------------------------------------------
5. Write a python program to drop two columns NaN and None from the dataframe data_gender .

An. code,
	data_gender = data_gender.dropna(axis=1)
	print("\n")
	'''del data_gender['Nan']
	del data_gender['None']'''   #will also work
	print(data_gender)
	
	o/p:
		   Year  Total  Males  Females
	0   2000/01   1054    309      741
	1   2001/02   1019    284      731
	2   2002/03   1275    427      848
	3   2003/04   1711    498     1213
	4   2004/05   2035    589     1442
	5   2005/06   2564    746     1786
	6   2006/07   3862   1047     2807
	7   2007/08   5018   1405     3613
	8   2008/09   7988   2077     5910
	9   2009/10  10571   2495     8074
	10  2010/11  11574   2919     8654
	11  2011/12  11736   2993     8740
----------------------------------------------------------------------------------------------
6. Write a python program to print the dataframe data_gender and remove NA values from it.

An. code,
	data_gender = data_gender.dropna(axis=1)
	print("\n")
	'''del data_gender['Nan']
	del data_gender['None']'''   #will also work
	print(data_gender)
	
	o/p:
		   Year  Total  Males  Females
	0   2000/01   1054    309      741
	1   2001/02   1019    284      731
	2   2002/03   1275    427      848
	3   2003/04   1711    498     1213
	4   2004/05   2035    589     1442
	5   2005/06   2564    746     1786
	6   2006/07   3862   1047     2807
	7   2007/08   5018   1405     3613
	8   2008/09   7988   2077     5910
	9   2009/10  10571   2495     8074
	10  2010/11  11574   2919     8654
	11  2011/12  11736   2993     8740
	
----------------------------------------------------------------------------------------------
7. Write a python program to reset the index as year.

An. code,
	data_gender.set_index('Year',inplace=True)
	print(data_gender)
	
	o/p:
			 Total  Males  Females
	Year                          
	2000/01   1054    309      741
	2001/02   1019    284      731
	2002/03   1275    427      848
	2003/04   1711    498     1213
	2004/05   2035    589     1442
	2005/06   2564    746     1786
	2006/07   3862   1047     2807
	2007/08   5018   1405     3613
	2008/09   7988   2077     5910
	2009/10  10571   2495     8074
	2010/11  11574   2919     8654
	2011/12  11736   2993     8740
----------------------------------------------------------------------------------------------
8. Write a python program to plot the data_gender and observe the obesity curve.
----------------------------------------------------------------------------------------------
9. Write a python program to read second sheet 7.2 as data_age.

An. code,
	xls = pd.ExcelFile('obes-phys-acti-diet.xls')
	df2 = pd.read_excel(xls, '7.2', header=None, skiprows = 5)
	df2_new = df2[1:13]
	print df2_new
	
	o/p:
         0      	1    2    3     4     5     6     7    8    9   10  11
	1   2000/01   1054  226   45   147   255   214    96   56   14 NaN NaN
	2   2001/02   1019  237   39   134   240   199    97   48   21 NaN NaN
	3   2002/03   1275  400   65   136   289   216    94   52   23 NaN NaN
	4   2003/04   1711  579   67   174   391   273   151   52   24 NaN NaN
	5   2004/05   2035  547  107   287   487   364   174   36   32 NaN NaN
	6   2005/06   2564  583   96   341   637   554   258   72   20 NaN NaN
	7   2006/07   3862  656  184   461  1069   872   459  118   43 NaN NaN
	8   2007/08   5018  747  228   564  1469  1198   598  157   53 NaN NaN
	9   2008/09   7988  775  322  1013  2359  2133  1099  221   63 NaN NaN
	10  2009/10  10571  632  361  1348  3132  3076  1555  378   87 NaN NaN
	11  2010/11  11574  525  375  1425  3277  3573  1820  456  115 NaN NaN
	12  2011/12  11736  495  391  1484  3104  3581  2119  468   94 NaN NaN
----------------------------------------------------------------------------------------------
10. Write a python program to rename the ‘Unnamed’ year column.

An. code,
	df2_new1 = df2_new.rename(columns={0:'Year',1:'Total'})
	print df2_new1
	
	o/p:
		Year  	 Total    2    3     4     5     6     7    8    9  10  11
	1   2000/01   1054  226   45   147   255   214    96   56   14 NaN NaN
	2   2001/02   1019  237   39   134   240   199    97   48   21 NaN NaN
	3   2002/03   1275  400   65   136   289   216    94   52   23 NaN NaN
	4   2003/04   1711  579   67   174   391   273   151   52   24 NaN NaN
	5   2004/05   2035  547  107   287   487   364   174   36   32 NaN NaN
	6   2005/06   2564  583   96   341   637   554   258   72   20 NaN NaN
	7   2006/07   3862  656  184   461  1069   872   459  118   43 NaN NaN
	8   2007/08   5018  747  228   564  1469  1198   598  157   53 NaN NaN
	9   2008/09   7988  775  322  1013  2359  2133  1099  221   63 NaN NaN
	10  2009/10  10571  632  361  1348  3132  3076  1555  378   87 NaN NaN
	11  2010/11  11574  525  375  1425  3277  3573  1820  456  115 NaN NaN
	12  2011/12  11736  495  391  1484  3104  3581  2119  468   94 NaN NaN
----------------------------------------------------------------------------------------------
11. Write a python program to drop Unnamed:10 and Unnamed:11 attributes.

An. code,
	df2_new2 = df2_new1.dropna(axis=1)
	print df2_new2
	
	o/p:
		Year  	 Total    2    3     4     5     6     7    8    9
	1   2000/01   1054  226   45   147   255   214    96   56   14
	2   2001/02   1019  237   39   134   240   199    97   48   21
	3   2002/03   1275  400   65   136   289   216    94   52   23
	4   2003/04   1711  579   67   174   391   273   151   52   24
	5   2004/05   2035  547  107   287   487   364   174   36   32
	6   2005/06   2564  583   96   341   637   554   258   72   20
	7   2006/07   3862  656  184   461  1069   872   459  118   43
	8   2007/08   5018  747  228   564  1469  1198   598  157   53
	9   2008/09   7988  775  322  1013  2359  2133  1099  221   63
	10  2009/10  10571  632  361  1348  3132  3076  1555  378   87
	11  2010/11  11574  525  375  1425  3277  3573  1820  456  115
	12  2011/12  11736  495  391  1484  3104  3581  2119  468   94
----------------------------------------------------------------------------------------------
12. Write a python program to drop empties and set index as year.

An. code,
	df2_new2.set_index('Year',inplace=True)
	print(df2_new2)
	
	o/p:
			Total    2     3     4     5     6     7    8    9
	Year                                                      
	2000/01   1054  226   45   147   255   214    96   56   14
	2001/02   1019  237   39   134   240   199    97   48   21
	2002/03   1275  400   65   136   289   216    94   52   23
	2003/04   1711  579   67   174   391   273   151   52   24
	2004/05   2035  547  107   287   487   364   174   36   32
	2005/06   2564  583   96   341   637   554   258   72   20
	2006/07   3862  656  184   461  1069   872   459  118   43
	2007/08   5018  747  228   564  1469  1198   598  157   53
	2008/09   7988  775  322  1013  2359  2133  1099  221   63
	2009/10  10571  632  361  1348  3132  3076  1555  378   87
	2010/11  11574  525  375  1425  3277  3573  1820  456  115
	2011/12  11736  495  391  1484  3104  3581  2119  468   94
----------------------------------------------------------------------------------------------
13. Write a python program to plot all the ages.
----------------------------------------------------------------------------------------------
14. Write a python program to remove ‘Total’ attribute and plot all ages.

An. code,
	del df2_new2['Total']
	print df2_new2

	o/p,
			   2    3     4     5     6     7    8    9
	Year                                               
	2000/01  226   45   147   255   214    96   56   14
	2001/02  237   39   134   240   199    97   48   21
	2002/03  400   65   136   289   216    94   52   23
	2003/04  579   67   174   391   273   151   52   24
	2004/05  547  107   287   487   364   174   36   32
	2005/06  583   96   341   637   554   258   72   20
	2006/07  656  184   461  1069   872   459  118   43
	2007/08  747  228   564  1469  1198   598  157   53
	2008/09  775  322  1013  2359  2133  1099  221   63
	2009/10  632  361  1348  3132  3076  1555  378   87
	2010/11  525  375  1425  3277  3573  1820  456  115
	2011/12  495  391  1484  3104  3581  2119  468   94
----------------------------------------------------------------------------------------------
15. Write a python program to plot under 16 and 25-34 age data.
	